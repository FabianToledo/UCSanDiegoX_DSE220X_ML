{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbor for spine injury classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework notebook we use **nearest neighbor classification** to classify back injuries for patients in a hospital, based on measurements of the shape and orientation of their pelvis and spine.\n",
    "\n",
    "The data set contains information from **310** patients. For each patient, there are: six measurements (the x) and a label (the y). The label has **3** possible values, `’NO’` (normal), `’DH’` (herniated disk), or `’SL’` (spondilolysthesis). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Before attempting this homework, please go through the <font color=\"magenta\">*Nearest neighbor for handwritten digit recognition*</font> notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import all necessary packages for the homework. Notice that we do **NOT** import any of the `sklearn` packages. This is because we want you to implement a nearest neighbor classifier **manually**, as in the <font color=\"magenta\">*Nearest neighbor for handwritten digit recognition*</font> notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the dataset. We divide the data into a training set of 248 patients and a separate test set of 62 patients. The following arrays are created:\n",
    "\n",
    "* **`trainx`** : The training data's features, one point per row.\n",
    "* **`trainy`** : The training data's labels.\n",
    "* **`testx`** : The test data's features, one point per row.\n",
    "* **`testy`** : The test data's labels.\n",
    "\n",
    "We will use the training set (`trainx` and `trainy`), with nearest neighbor classification, to predict labels for the test data (`testx`). We will then compare these predictions with the correct labels, `testy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we code the three labels as `0. = ’NO’, 1. = ’DH’, 2. = ’SL’`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 63.03  22.55  39.61  40.48  98.67  -0.25]\n",
      " [ 39.06  10.06  25.02  29.   114.41   4.56]\n",
      " [ 68.83  22.22  50.09  46.61 105.99  -3.53]\n",
      " ...\n",
      " [ 61.45  22.69  46.17  38.75 125.67  -2.71]\n",
      " [ 45.25   8.69  41.58  36.56 118.55   0.21]\n",
      " [ 33.84   5.07  36.64  28.77 123.95  -0.2 ]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[ 43.92  14.18  37.83  29.74 134.46   6.45]\n",
      " [ 54.92  21.06  42.2   33.86 125.21   2.43]\n",
      " [ 63.07  24.41  54.    38.66 106.42  15.78]\n",
      " [ 45.54  13.07  30.3   32.47 117.98  -4.99]\n",
      " [ 36.13  22.76  29.    13.37 115.58  -3.24]\n",
      " [ 54.12  26.65  35.33  27.47 121.45   1.57]\n",
      " [ 26.15  10.76  14.    15.39 125.2  -10.09]\n",
      " [ 43.58  16.51  47.    27.07 109.27   8.99]\n",
      " [ 44.55  21.93  26.79  22.62 111.07   2.65]\n",
      " [ 66.88  24.89  49.28  41.99 113.48  -2.01]\n",
      " [ 50.82  15.4   42.53  35.42 112.19  10.87]\n",
      " [ 46.39  11.08  32.14  35.31  98.77   6.39]\n",
      " [ 44.94  17.44  27.78  27.49 117.98   5.57]\n",
      " [ 38.66  12.99  40.    25.68 124.91   2.7 ]\n",
      " [ 59.6   32.    46.56  27.6  119.33   1.47]\n",
      " [ 31.48   7.83  24.28  23.66 113.83   4.39]\n",
      " [ 32.09   6.99  36.    25.1  132.26   6.41]\n",
      " [ 35.7   19.44  20.7   16.26 137.54  -0.26]\n",
      " [ 55.84  28.85  47.69  27.   123.31   2.81]\n",
      " [ 52.42  19.01  35.87  33.41 116.56   1.69]\n",
      " [ 85.68  38.65  82.68  47.03 120.84  61.96]\n",
      " [ 82.41  29.28  77.05  53.13 117.04  62.77]\n",
      " [ 43.72   9.81  52.    33.91  88.43  40.88]\n",
      " [ 86.47  40.3   61.14  46.17  97.4   55.75]\n",
      " [ 74.47  33.28  66.94  41.19 146.47 124.98]\n",
      " [ 70.25  10.34  76.37  59.91 119.24  32.67]\n",
      " [ 72.64  18.93  68.    53.71 116.96  25.38]\n",
      " [ 71.24   5.27  86.    65.97 110.7   38.26]\n",
      " [ 63.77  12.76  65.36  51.01  89.82  56.  ]\n",
      " [ 58.83  37.58 125.74  21.25 135.63 117.31]\n",
      " [ 74.85  13.91  62.69  60.95 115.21  33.17]\n",
      " [ 75.3   16.67  61.3   58.63 118.88  31.58]\n",
      " [ 63.36  20.02  67.5   43.34 131.    37.56]\n",
      " [ 67.51  33.28  96.28  34.24 145.6   88.3 ]\n",
      " [ 76.31  41.93  93.28  34.38 132.27 101.22]\n",
      " [ 73.64   9.71  63.    63.92  98.73  26.98]\n",
      " [ 56.54  14.38  44.99  42.16 101.72  25.77]\n",
      " [ 80.11  33.94  85.1   46.17 125.59 100.29]\n",
      " [ 95.48  46.55  59.    48.93  96.68  77.28]\n",
      " [ 74.09  18.82  76.03  55.27 128.41  73.39]\n",
      " [ 87.68  20.37  93.82  67.31 120.94  76.73]\n",
      " [ 48.26  16.42  36.33  31.84  94.88  28.34]\n",
      " [ 38.51  16.96  35.11  21.54 127.63   7.99]\n",
      " [ 54.92  18.97  51.6   35.95 125.85   2.  ]\n",
      " [ 44.36   8.95  46.9   35.42 129.22   4.99]\n",
      " [ 48.32  17.45  48.    30.87 128.98  -0.91]\n",
      " [ 45.7   10.66  42.58  35.04 130.18  -3.39]\n",
      " [ 30.74  13.35  35.9   17.39 142.41  -2.01]\n",
      " [ 50.91   6.68  30.9   44.24 118.15  -1.06]\n",
      " [ 38.13   6.56  50.45  31.57 132.11   6.34]\n",
      " [ 51.62  15.97  35.    35.66 129.39   1.01]\n",
      " [ 64.31  26.33  50.96  37.98 106.18   3.12]\n",
      " [ 44.49  21.79  31.47  22.7  113.78  -0.28]\n",
      " [ 54.95   5.87  53.    49.09 126.97  -0.63]\n",
      " [ 56.1   13.11  62.64  43.   116.23  31.17]\n",
      " [ 69.4   18.9   75.97  50.5  103.58  -0.44]\n",
      " [ 89.83  22.64  90.56  67.2  100.5    3.04]\n",
      " [ 59.73   7.72  55.34  52.   125.17   3.24]\n",
      " [ 63.96  16.06  63.12  47.9  142.36   6.3 ]\n",
      " [ 61.54  19.68  52.89  41.86 118.69   4.82]\n",
      " [ 38.05   8.3   26.24  29.74 123.8    3.89]\n",
      " [ 43.44  10.1   36.03  33.34 137.44  -3.11]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Load data set and code labels as 0 = ’NO’, 1 = ’DH’, 2 = ’SL’\n",
    "labels = [b'NO', b'DH', b'SL']\n",
    "data_set = np.loadtxt('column_3C.dat', converters = {6: lambda x: labels.index(x)}, delimiter=' ')\n",
    "\n",
    "# Separate features from labels\n",
    "measurements_x = data_set[:,0:6]\n",
    "labels_y =  data_set[:,6]\n",
    "\n",
    "# print(measurements_x)\n",
    "# print(labels_y)\n",
    "\n",
    "# Divide into training and test set\n",
    "training_indices = list(range(0,20)) + list(range(40,188)) + list(range(230,310))\n",
    "test_indices = list(range(20,40)) + list(range(188,230))\n",
    "\n",
    "# print(training_indices)\n",
    "# print(test_indices)\n",
    "\n",
    "trainx = measurements_x[training_indices,:]\n",
    "trainy = labels_y[training_indices]\n",
    "testx = measurements_x[test_indices,:]\n",
    "testy = labels_y[test_indices]\n",
    "\n",
    "print(trainx)\n",
    "print(trainy)\n",
    "print(testx)\n",
    "print(testy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nearest neighbor classification with L2 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will build a nearest neighbor classifier based on L2 (*Euclidean*) distance.\n",
    "\n",
    "<font color=\"magenta\">**For you to do:**</font> Write a function, **NN_L2**, which takes as input the training data (`trainx` and `trainy`) and the test points (`testx`) and predicts labels for these test points using 1-NN classification. These labels should be returned in a `numpy` array with one entry per test point. For **NN_L2**, the L2 norm should be used as the distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font  style=\"color:blue\"> **Code**</font>\n",
    "```python\n",
    "# test function \n",
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "print( type( testy_L2) )\n",
    "print( len(testy_L2) )\n",
    "print( testy_L2[40:50] )\n",
    "```\n",
    "\n",
    "<font  style=\"color:magenta\"> **Output**</font>\n",
    "```\n",
    "<class 'numpy.ndarray'>\n",
    "62\n",
    "[ 2.  2.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this Cell\n",
    "\n",
    "def L2_dist(train_point, test_point):\n",
    "    return np.sum(np.square(train_point-test_point))\n",
    "\n",
    "def NN_prediction(trainx, trainy, test_point, dist_func):\n",
    "    \n",
    "    distances = [dist_func(trainx[i], test_point) for i in range(len(trainx)) ]\n",
    "    NN_ind = np.argmin(distances)\n",
    "    \n",
    "    return trainy[NN_ind]\n",
    "\n",
    "def NN_L2(trainx, trainy, testx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    return np.array([NN_prediction(trainx, trainy, testx[i], L2_dist) for i in range(len(testx))])\n",
    "    ### END SOLUTION\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you are done, run the cell below to check your function. If an error is triggered, you should go back and revise your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "\n",
    "assert( type( testy_L2).__name__ == 'ndarray' )\n",
    "assert( len(testy_L2) == 62 ) \n",
    "assert( np.all( testy_L2[50:60] == [ 0.,  0.,  0.,  0.,  2.,  0.,  2.,  0.,  0.,  0.] )  )\n",
    "assert( np.all( testy_L2[0:10] == [ 0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.] ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Nearest neighbor classification with L1 distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute nearest neighbors using the L1 distance (sometimes called *Manhattan Distance*).\n",
    "\n",
    "<font color=\"magenta\">**For you to do:**</font> Write a function, **NN_L1**, which again takes as input the arrays `trainx`, `trainy`, and `testx`, and predicts labels for the test points using 1-nearest neighbor classification. For **NN_L1**, the L1 distance metric should be used. As before, the predicted labels should be returned in a `numpy` array with one entry per test point.\n",
    "\n",
    "Notice that **NN_L1** and **NN_L2** may well produce different predictions on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font  style=\"color:blue\"> **Code**</font>\n",
    "```python\n",
    "# test function \n",
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "testy_L1 = NN_L1(trainx, trainy, testx)\n",
    "\n",
    "print( type( testy_L1) )\n",
    "print( len(testy_L1) )\n",
    "print( testy_L1[40:50] )\n",
    "print( all(testy_L1 == testy_L2) )\n",
    "```\n",
    "\n",
    "<font  style=\"color:magenta\"> **Output**</font>\n",
    "```\n",
    "<class 'numpy.ndarray'>\n",
    "62\n",
    "[ 2.  2.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "False\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this Cell\n",
    "def L1_dist(train_point, test_point):\n",
    "    return np.sum(np.abs(train_point-test_point))\n",
    "\n",
    "def NN_L1(trainx, trainy, testx):\n",
    "    # inputs: trainx, trainy, testx <-- as defined above\n",
    "    # output: an np.array of the predicted values for testy \n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    return np.array([NN_prediction(trainx, trainy, testx[i], L1_dist) for i in range(len(testx))])\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, use the following cell to check your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_L1 = NN_L1(trainx, trainy, testx)\n",
    "testy_L2 = NN_L2(trainx, trainy, testx)\n",
    "\n",
    "assert( type( testy_L1).__name__ == 'ndarray' )\n",
    "assert( len(testy_L1) == 62 ) \n",
    "assert( not all(testy_L1 == testy_L2) )\n",
    "assert( all(testy_L1[50:60]== [ 0.,  2.,  1.,  0.,  2.,  0.,  0.,  0.,  0.,  0.]) )\n",
    "assert( all( testy_L1[0:10] == [ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test errors and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the L1 and L2 distance functions yield different error rates for nearest neighbor classification of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of NN_L1:  22.58064516129032\n",
      "Error rate of NN_L2:  20.967741935483872\n"
     ]
    }
   ],
   "source": [
    "def error_rate(testy, testy_fit):\n",
    "    return float(sum(testy!=testy_fit))/len(testy) \n",
    "\n",
    "print(\"Error rate of NN_L1: \", error_rate(testy,testy_L1) * 100)\n",
    "print(\"Error rate of NN_L2: \", error_rate(testy,testy_L2) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look a bit more deeply into the specific types of errors made by nearest neighbor classification, by constructing the <font color=\"magenta\">*confusion matrix*</font>.\n",
    "\n",
    "Since there are three labels, the confusion matrix is a 3x3 matrix whose rows correspond to the true label and whose columns correspond to the predicted label. For example, the entry at row DH, column SL, contains the number of test points whose correct label was DH but which were classified as SL.\n",
    "\n",
    "<img style=\"width:200px\" src=\"confusion_matrix.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, **confusion**, which takes as input the true labels for the test set (that is, `testy`) as well as the predicted labels and returns the confusion matrix. The confusion matrix should be a `np.array` of shape `(3,3)` . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font  style=\"color:blue\"> **Code**</font>\n",
    "```python\n",
    "L2_neo = confusion(testy, testy_L2)  \n",
    "print( type(L2_neo) )\n",
    "print( L2_neo.shape )\n",
    "print( L2_neo )\n",
    "```\n",
    "\n",
    "<font  style=\"color:magenta\"> **Output**</font>\n",
    "```\n",
    "<class 'numpy.ndarray'>\n",
    "(3, 3)\n",
    "[[ 17.   1.   2.]\n",
    " [ 10.  10.   0.]\n",
    " [  0.   0.  22.]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this cell\n",
    "\n",
    "def confusion(testy,testy_fit):\n",
    "    # inputs: the correct labels, the fitted NN labels \n",
    "    # output: a 3x3 np.array representing the confusion matrix as above\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    confusion_mtx = np.zeros((3,3))\n",
    "    for i in range(len(testy)):\n",
    "        confusion_mtx[int(testy[i]),int(testy_fit[i])] = confusion_mtx[int(testy[i]),int(testy_fit[i])] + 1\n",
    "    \n",
    "    return (confusion_mtx)\n",
    "    ### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check your code by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function\n",
    "\n",
    "L1_neo = confusion(testy, testy_L1) \n",
    "assert( type(L1_neo).__name__ == 'ndarray' )\n",
    "assert( L1_neo.shape == (3,3) )\n",
    "assert( np.all(L1_neo == [[ 16.,  2.,  2.],[ 10.,  10.,  0.],[ 0.,  0.,  22.]]) )\n",
    "L2_neo = confusion(testy, testy_L2)  \n",
    "assert( np.all(L2_neo == [[ 17.,  1.,  2.],[ 10.,  10.,  0.],[ 0.,  0.,  22.]]) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Some questions for you\n",
    "\n",
    "*Note down the answers to these, since you will need to enter them as part of this week's assignment.*\n",
    "\n",
    "* In the test set, which class (NO, DH, or SL) was **most frequently** misclassified by the L1-based nearest neighbor classifier?\n",
    "* In the test set, which class (NO, DH, or SL) was **never** misclassified by the L2-based nearest neighbor classifier?\n",
    "* On **how many** of the test points did the two classification schemes (based on L1 and L2 distance) yield *different* predictions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3, 3)\n",
      "[[16.  2.  2.]\n",
      " [10. 10.  0.]\n",
      " [ 0.  0. 22.]]\n",
      "\n",
      "\n",
      "========================================\n",
      "<class 'numpy.ndarray'>\n",
      "(3, 3)\n",
      "[[17.  1.  2.]\n",
      " [10. 10.  0.]\n",
      " [ 0.  0. 22.]]\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "L1 based NN misclassified count: \n",
      "[ 4. 10.  0.]\n",
      "\n",
      "Most frequently misclassified:  b'DH'\n",
      "\n",
      "Never misclassified:  b'SL'\n",
      "========================================\n",
      "\n",
      "L2 based NN misclassified count: \n",
      "[ 3. 10.  0.]\n",
      "\n",
      "Most frequently misclassified:  b'DH'\n",
      "\n",
      "Never misclassified:  b'SL'\n",
      "========================================\n",
      "\n",
      "On 7 of the test points the two classification schemes yield *different* predictions \n"
     ]
    }
   ],
   "source": [
    "L1_neo = confusion(testy, testy_L1)  \n",
    "print( type(L1_neo) )\n",
    "print( L1_neo.shape )\n",
    "print( L1_neo )\n",
    "print('\\n')\n",
    "print(\"========================================\")\n",
    "L2_neo = confusion(testy, testy_L2)  \n",
    "print( type(L2_neo) )\n",
    "print( L2_neo.shape )\n",
    "print( L2_neo )\n",
    "print('\\n')\n",
    "print(\"========================================\")\n",
    "print(\"\\nL1 based NN misclassified count: \")\n",
    "L1_mis_count = np.sum(L1_neo, axis=1)-np.sum(L1_neo*np.identity(3), axis=1)\n",
    "print(L1_mis_count)\n",
    "print(\"\\nMost frequently misclassified: \", labels[np.argmax(L1_mis_count)])\n",
    "print(\"\\nNever misclassified: \", labels[np.squeeze(np.argwhere(L1_mis_count==0))])\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"\\nL2 based NN misclassified count: \")\n",
    "L2_mis_count = np.sum(L2_neo, axis=1)-np.sum(L2_neo*np.identity(3), axis=1)\n",
    "print(L2_mis_count)\n",
    "print(\"\\nMost frequently misclassified: \", labels[np.argmax(L2_mis_count)])\n",
    "print(\"\\nNever misclassified: \", labels[np.squeeze(np.argwhere(L2_mis_count==0))])\n",
    "\n",
    "print(\"========================================\")\n",
    "\n",
    "print(\"\\nOn {0} of the test points the two classification schemes yield *different* predictions \".format(np.sum(testy_L1 != testy_L2)))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "670px",
    "left": "0px",
    "right": "1145px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
